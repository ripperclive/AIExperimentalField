{
    "sourceFile": "src/memoryChat.js",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 17,
            "patches": [
                {
                    "date": 1683718307833,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1683718510622,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -121,9 +121,9 @@\n  * vectorChain: 使用向量库\n  */\n async function memoryChat(inputValue) {\n \n-    const response = await memoryChain.call({ input: inputValue })\n+    const response = await restrictMemoryChain.call({ input: inputValue })\n \n     console.log(response)\n     console.log({ 'AI的内心OS': await intelligenceMemory.loadMemoryVariables({}) })\n \n"
                },
                {
                    "date": 1683718589294,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -121,9 +121,9 @@\n  * vectorChain: 使用向量库\n  */\n async function memoryChat(inputValue) {\n \n-    const response = await restrictMemoryChain.call({ input: inputValue })\n+    const response = await intelligenceMemoryChain.call({ input: inputValue })\n \n     console.log(response)\n     console.log({ 'AI的内心OS': await intelligenceMemory.loadMemoryVariables({}) })\n \n"
                },
                {
                    "date": 1683718718726,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -121,9 +121,9 @@\n  * vectorChain: 使用向量库\n  */\n async function memoryChat(inputValue) {\n \n-    const response = await intelligenceMemoryChain.call({ input: inputValue })\n+    const response = await vectorChain.call({ input: inputValue })\n \n     console.log(response)\n     console.log({ 'AI的内心OS': await intelligenceMemory.loadMemoryVariables({}) })\n \n"
                },
                {
                    "date": 1683719261418,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -93,12 +93,12 @@\n     { input: \"我最喜欢的代步工具是AC-130\" },\n     { output: \"那你一定很有钱\" }\n )\n // 输出一下看看效果\n-// console.log(\n-//     await vectorStoreMemory.loadMemoryVariables({ prompt: \"我是一个什么东西\" })\n-// )\n-// { history: 'input: 我的性别是武装直升机\\noutput: ……' }\n+console.log(\n+    await vectorStoreMemory.loadMemoryVariables({ prompt: \"我是一个什么东西\" })\n+)\n+{ history: 'input: 我的性别是武装直升机\\noutput: ……' }\n \n const vectorPrompt =\n     PromptTemplate.fromTemplate(`The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n \n"
                },
                {
                    "date": 1683719331813,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -85,8 +85,12 @@\n     { input: \"我的性别是武装直升机\" },\n     { output: \"天哪，你一定是个美国人\" }\n )\n await vectorStoreMemory.saveContext(\n+    { input: \"你好，我叫jim\" },\n+    { output: \"是的，你叫jim\" }\n+)\n+await vectorStoreMemory.saveContext(\n     { input: \"我最喜欢的动物是人\" },\n     { output: \"那太好了\" }\n )\n await vectorStoreMemory.saveContext(\n@@ -96,9 +100,9 @@\n // 输出一下看看效果\n console.log(\n     await vectorStoreMemory.loadMemoryVariables({ prompt: \"我是一个什么东西\" })\n )\n-{ history: 'input: 我的性别是武装直升机\\noutput: ……' }\n+// { history: 'input: 我的性别是武装直升机\\noutput: ……' }\n \n const vectorPrompt =\n     PromptTemplate.fromTemplate(`The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n \n"
                },
                {
                    "date": 1683719336889,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -85,10 +85,10 @@\n     { input: \"我的性别是武装直升机\" },\n     { output: \"天哪，你一定是个美国人\" }\n )\n await vectorStoreMemory.saveContext(\n-    { input: \"你好，我叫jim\" },\n-    { output: \"是的，你叫jim\" }\n+    { input: \"你好,我叫jim\" },\n+    { output: \"是的,你叫jim\" }\n )\n await vectorStoreMemory.saveContext(\n     { input: \"我最喜欢的动物是人\" },\n     { output: \"那太好了\" }\n"
                },
                {
                    "date": 1683719381519,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -98,9 +98,9 @@\n     { output: \"那你一定很有钱\" }\n )\n // 输出一下看看效果\n console.log(\n-    await vectorStoreMemory.loadMemoryVariables({ prompt: \"我是一个什么东西\" })\n+    await vectorStoreMemory.loadMemoryVariables({ prompt: \"你了解我嘛\" })\n )\n // { history: 'input: 我的性别是武装直升机\\noutput: ……' }\n \n const vectorPrompt =\n"
                },
                {
                    "date": 1683719394208,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -85,9 +85,9 @@\n     { input: \"我的性别是武装直升机\" },\n     { output: \"天哪，你一定是个美国人\" }\n )\n await vectorStoreMemory.saveContext(\n-    { input: \"你好,我叫jim\" },\n+    { input: \"你好,我的名字叫jim\" },\n     { output: \"是的,你叫jim\" }\n )\n await vectorStoreMemory.saveContext(\n     { input: \"我最喜欢的动物是人\" },\n@@ -98,9 +98,9 @@\n     { output: \"那你一定很有钱\" }\n )\n // 输出一下看看效果\n console.log(\n-    await vectorStoreMemory.loadMemoryVariables({ prompt: \"你了解我嘛\" })\n+    await vectorStoreMemory.loadMemoryVariables({ prompt: \"我的名字是什么\" })\n )\n // { history: 'input: 我的性别是武装直升机\\noutput: ……' }\n \n const vectorPrompt =\n"
                },
                {
                    "date": 1683719411307,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -97,11 +97,11 @@\n     { input: \"我最喜欢的代步工具是AC-130\" },\n     { output: \"那你一定很有钱\" }\n )\n // 输出一下看看效果\n-console.log(\n-    await vectorStoreMemory.loadMemoryVariables({ prompt: \"我的名字是什么\" })\n-)\n+// console.log(\n+//     await vectorStoreMemory.loadMemoryVariables({ prompt: \"我的名字是什么\" })\n+// )\n // { history: 'input: 我的性别是武装直升机\\noutput: ……' }\n \n const vectorPrompt =\n     PromptTemplate.fromTemplate(`The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n"
                },
                {
                    "date": 1683719449241,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -132,7 +132,8 @@\n     console.log({ 'AI的内心OS': await intelligenceMemory.loadMemoryVariables({}) })\n \n }\n \n+memoryChat('你还记得我叫什么吗')\n \n \n export default memoryChat\n\\ No newline at end of file\n"
                },
                {
                    "date": 1683719506370,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -128,9 +128,9 @@\n \n     const response = await vectorChain.call({ input: inputValue })\n \n     console.log(response)\n-    console.log({ 'AI的内心OS': await intelligenceMemory.loadMemoryVariables({}) })\n+    console.log({ 'AI的内心OS': await vectorStoreMemory.loadMemoryVariables({}) })\n \n }\n \n memoryChat('你还记得我叫什么吗')\n"
                },
                {
                    "date": 1683719525731,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -128,9 +128,9 @@\n \n     const response = await vectorChain.call({ input: inputValue })\n \n     console.log(response)\n-    console.log({ 'AI的内心OS': await vectorStoreMemory.loadMemoryVariables({}) })\n+    console.log({ 'AI的内心OS': await intelligenceMemory.loadMemoryVariables({}) })\n \n }\n \n memoryChat('你还记得我叫什么吗')\n"
                },
                {
                    "date": 1683719620616,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -133,7 +133,9 @@\n \n }\n \n memoryChat('你还记得我叫什么吗')\n+memoryChat('你还记得我的性别吗')\n \n \n+\n export default memoryChat\n\\ No newline at end of file\n"
                },
                {
                    "date": 1683719630105,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -133,9 +133,12 @@\n \n }\n \n memoryChat('你还记得我叫什么吗')\n-memoryChat('你还记得我的性别吗')\n+setTimeout(() => {\n+    memoryChat('你还记得我的性别吗')\n \n+}, 10000);\n \n \n+\n export default memoryChat\n\\ No newline at end of file\n"
                },
                {
                    "date": 1683719685303,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -98,9 +98,9 @@\n     { output: \"那你一定很有钱\" }\n )\n // 输出一下看看效果\n // console.log(\n-//     await vectorStoreMemory.loadMemoryVariables({ prompt: \"我的名字是什么\" })\n+//     await vectorStoreMemory.loadMemoryVariables({ prompt: \"我的性别是什么\" })\n // )\n // { history: 'input: 我的性别是武装直升机\\noutput: ……' }\n \n const vectorPrompt =\n"
                },
                {
                    "date": 1683719954449,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -97,11 +97,11 @@\n     { input: \"我最喜欢的代步工具是AC-130\" },\n     { output: \"那你一定很有钱\" }\n )\n // 输出一下看看效果\n-// console.log(\n-//     await vectorStoreMemory.loadMemoryVariables({ prompt: \"我的性别是什么\" })\n-// )\n+console.log(\n+    await vectorStoreMemory.loadMemoryVariables({ prompt: \"我的性别是什么\" })\n+)\n // { history: 'input: 我的性别是武装直升机\\noutput: ……' }\n \n const vectorPrompt =\n     PromptTemplate.fromTemplate(`The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n@@ -132,13 +132,7 @@\n     console.log({ 'AI的内心OS': await intelligenceMemory.loadMemoryVariables({}) })\n \n }\n \n-memoryChat('你还记得我叫什么吗')\n-setTimeout(() => {\n-    memoryChat('你还记得我的性别吗')\n \n-}, 10000);\n \n-\n-\n export default memoryChat\n\\ No newline at end of file\n"
                },
                {
                    "date": 1683720009051,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -97,11 +97,11 @@\n     { input: \"我最喜欢的代步工具是AC-130\" },\n     { output: \"那你一定很有钱\" }\n )\n // 输出一下看看效果\n-console.log(\n-    await vectorStoreMemory.loadMemoryVariables({ prompt: \"我的性别是什么\" })\n-)\n+// console.log(\n+//     await vectorStoreMemory.loadMemoryVariables({ prompt: \"我的性别是什么\" })\n+// )\n // { history: 'input: 我的性别是武装直升机\\noutput: ……' }\n \n const vectorPrompt =\n     PromptTemplate.fromTemplate(`The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n"
                }
            ],
            "date": 1683718307833,
            "name": "Commit-0",
            "content": "import chat from \"./components/chat.js\";\nimport chatPrompt from \"./components/template.js\";\nimport { PromptTemplate } from \"langchain/prompts\";\n\n// 缓存\nimport { BufferMemory } from \"langchain/memory\";\nimport { LLMChain } from \"langchain/chains\";\nimport { ConversationChain } from \"langchain/chains\";\nimport { BufferWindowMemory } from \"langchain/memory\";\nimport { ConversationSummaryMemory } from \"langchain/memory\";\n// openAI官方提供的文本分析器，可以将文本用向量来表示,也可以用来生成摘要。 需要KEY\nimport { OpenAIEmbeddings } from \"langchain/embeddings/openai\";\nimport { MemoryVectorStore } from \"langchain/vectorstores/memory\";\nimport { VectorStoreRetrieverMemory } from \"langchain/memory\";\n\n\n// new一个\nconst memory = new BufferMemory({ returnMessages: true, memoryKey: \"history\" })\n\n// 因为使用的是ConversationChain，可以顺路把模板也塞进去\nconst memoryChain = new ConversationChain({\n    memory: memory,\n    prompt: chatPrompt,\n    llm: chat,\n})\n//------------------------------------------------------------------------------------------------------------\n\n// 如果频繁聊天占用内存过大，也可以限制窗口大小\n// k:1 表示限制窗口大小为一次会话\nconst restrictMemory = new BufferWindowMemory({ k: 1, returnMessages: true, memoryKey: \"history\" })\nconst restrictMemoryChain = new ConversationChain({\n    memory: restrictMemory,\n    prompt: chatPrompt,\n    llm: chat,\n})\n//------------------------------------------------------------------------------------------------------------\n// 如果输入一些复杂的组合信息，可以选择让AI去缓存历史信息的摘要，而不是去死记硬背聊天记录\n// 需要配合模板一起使用\nconst intelligenceMemory = new ConversationSummaryMemory({\n    memoryKey: \"chat_history\",\n    llm: chat\n});\n\nconst prompt =\n    PromptTemplate.fromTemplate(`The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n  Current conversation:\n  {chat_history}\n  Human: {input}\n  AI:`);\nconst intelligenceMemoryChain = new LLMChain({ llm: chat, prompt, memory: intelligenceMemory });\n/**\n * 既然AI会整合聊天记录，并且组织成一个上下文，如果在用户和AI通话前使用SystemChatMessage提前和AI打好招呼铺垫一下上下文？\n *     （😅那为啥不直接拼模板啊？）\n *     const response = await chat.call([\n *     new SystemChatMessage(\n *         '我叫露丝，我的生日是4月30日'\n *     ),\n *     new HumanChatMessage(\n *         { input: inputValue }\n *     )\n * ])\n * 然而并不行，相关功能肯定是有，但是不能这么写\n*/\n\n\n// 缓存的内容是存储在内存中的，如果需要持久化保存，官网给的例子使用Motorhead\n// 我没写过后端，不知道用户的聊天记录或者聊天摘要全部存在缓存里会不会给服务器干💥，鉴于学习成本这块先略过\n//------------------------------------------------------------------------------------------------------------\n\n\n// 也可以将对话数据存储在VectorDB中，VectorDB是一个高性能的向量检索库，基于类似HNSW的算法来进行快速的相似度搜索\n// HNSW相关的库后面也会用到，比如知识库\nconst vectorStore = new MemoryVectorStore(new OpenAIEmbeddings({ openAIApiKey: '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' }))\n// \nconst vectorStoreMemory = new VectorStoreRetrieverMemory({\n    // 1是要回溯的文本/对话数量\n    vectorStoreRetriever: vectorStore.asRetriever(1),\n    memoryKey: \"history\",\n});\n\n\n\n// 在开始之前可以先将一些信息保存在缓存中\nawait vectorStoreMemory.saveContext(\n    { input: \"我的性别是武装直升机\" },\n    { output: \"天哪，你一定是个美国人\" }\n)\nawait vectorStoreMemory.saveContext(\n    { input: \"我最喜欢的动物是人\" },\n    { output: \"那太好了\" }\n)\nawait vectorStoreMemory.saveContext(\n    { input: \"我最喜欢的代步工具是AC-130\" },\n    { output: \"那你一定很有钱\" }\n)\n// 输出一下看看效果\n// console.log(\n//     await vectorStoreMemory.loadMemoryVariables({ prompt: \"我是一个什么东西\" })\n// )\n// { history: 'input: 我的性别是武装直升机\\noutput: ……' }\n\nconst vectorPrompt =\n    PromptTemplate.fromTemplate(`The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n\nRelevant pieces of previous conversation:\n{history}\n\n(You do not need to use these pieces of information if not relevant)\n\nCurrent conversation:\nHuman: {input}\nAI:`);\n\nconst vectorChain = new LLMChain({ llm: chat, prompt:vectorPrompt, memory:vectorStoreMemory });\n\n\n/**\n * memoryChain: 普通缓存\n * restrictMemoryChain: 限制聊天窗口\n * intelligenceMemoryChain: 智能缓存，根据聊天内容生成摘要\n * vectorChain: 使用向量库\n */\nasync function memoryChat(inputValue) {\n\n    const response = await memoryChain.call({ input: inputValue })\n\n    console.log(response)\n    console.log({ 'AI的内心OS': await intelligenceMemory.loadMemoryVariables({}) })\n\n}\n\n\n\nexport default memoryChat"
        }
    ]
}